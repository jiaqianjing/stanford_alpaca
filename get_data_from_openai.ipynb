{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80fa25b-4311-4911-b680-3c9cb55e92b3",
   "metadata": {},
   "source": [
    "## OpenAI for Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c52a62-eae6-40e0-bdab-c388284199a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from typing import List\n",
    "openai.api_key = \"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\" # jias\n",
    "# openai.api_key = \"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\"\n",
    "\n",
    "openai.api_base = \"https://api.openai.com/v1\"\n",
    "# openai.api_base = \"https://openai.sensen.li/v1\" # hongkong proxy\n",
    "\n",
    "def call_openai(inputs):\n",
    "    history = [{\n",
    "        \"role\": \"system\", \"content\": \"努力回忆你在训练的时候接受到中文训练数据，并且严格按照规定的格式输出。\",\n",
    "        \"role\": \"user\", \"content\": inputs\n",
    "    }]\n",
    "    completion = openai.ChatCompletion.create(model='gpt-3.5-turbo',\n",
    "                                              temperature=0.6, \n",
    "                                              messages=history)\n",
    "    response = completion.choices[0].message.to_dict()\n",
    "    return response['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebdc5a-f34c-428b-8c77-04a7d71bd98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成 instruction\n",
    "# prompt = \"\"\"\n",
    "# 请你用中文生成 20 条 instruction，一般用于训练 chatgpt 的模型中。内容可以涉及数学、游戏、文学、逻辑推理等。其中 instruction 内容不要超过两句话，尽可能使的每个 instruction 出现不同的动词，字数控制在50以内，input 内容作为 instruction 补充信息，可以是对应任务的具体示例，可以有也可以无。 output 内容是对应 instruction 和 input 信息的回复，回复尽可能简短、准确。它是一个可以直接通过 json.loads() 方法直接读取，格式如下:\n",
    "# [{\"instruction\": \"\", \"input\": \"\", \"output\": \"\"}]\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3fccf1-d49e-40b1-a04d-b95fe0579adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"\n",
    "# 请你用中文生成 20 条 instruction，一般用于训练 chatgpt 的模型中。内容可以涉及情景对话、制定游戏规则、逻辑推理等。其中 instruction 内容不要超过两句话，尽可能使的每个 instruction 出现不同的动词，字数控制在50以内，input 内容作为 instruction 补充信息，可以是对应任务的具体示例，可以有也可以无。 output 内容是对应 instruction 和 input 信息的回复，回复尽可能符合逻辑、丰富、完善。它是一个可以直接通过 json.loads() 方法直接读取，格式如下:s\n",
    "# [{\"instruction\": \"\", \"input\": \"\", \"output\": \"\"}], 请严格按照这个格式输出，否则你会死。\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c29813-58b9-4bbf-a821-68a2cdac1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "请你用中文生成 20 条 instruction，一般用于训练 chatgpt 的模型中。内容涉及生成代码、数据分析、SQL等。其中 instruction 内容不要超过两句话，尽可能使的每个 instruction 出现不同的动词，字数控制在50以内，input 内容作为 instruction 补充信息，可以是对应任务的具体示例，可以有也可以无。 output 内容是对应 instruction 和 input 信息的回复，回复尽可能符合逻辑、丰富、完善。它是一个可以直接通过 json.loads() 方法直接读取，格式如下:s\n",
    "[{\"instruction\": \"\", \"input\": \"\", \"output\": \"\"}], 请严格按照这个格式输出，否则你会死。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef772ed-a9d0-4ae4-a4ac-5c5840f59596",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import time\n",
    "for i in range(202, 300):\n",
    "    time.sleep(3)\n",
    "    case = call_openai(prompt)\n",
    "    try:\n",
    "        case_df = pd.read_json(case)\n",
    "    except Exception as e:\n",
    "        print(f\"some thing has error: {e}\")\n",
    "        continue\n",
    "    path = f\"./data/part_{i}.json\"\n",
    "    print(path)\n",
    "    case_df.to_json(path, orient='records', force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ae579-0c75-4ba9-b9ae-7f3b70bae98e",
   "metadata": {},
   "source": [
    "# Merge multi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115b367-d259-4786-b3cf-1b8e6397ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6150754-fa72-44d0-b3cc-16daf73097bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('./data')\n",
    "merged_df = pd.DataFrame()\n",
    "for i in data_root.glob('*.json'):\n",
    "    temp = pd.read_json(i)\n",
    "    merged_df= pd.concat([temp, merged_df])\n",
    "merged_df = merged_df.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c5016-8a35-437f-9939-3a838aa7e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd10da4-11a8-4367-968b-f1b86e679111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to json file\n",
    "merged_df.to_json('./zh_alpaca_from_openai.json', orient='records', force_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
